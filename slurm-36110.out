2022-05-25 03:59:21 - [33m[1mWARNING[0m - Error while loading config file: /nfs/projects/mbzuai/ashaker_2/mobilevit/config/detection/ssd_mobilenext_320.yaml
2022-05-25 03:59:21 - [33m[1mWARNING[0m - Error message: while scanning a simple key
  in "/nfs/projects/mbzuai/ashaker_2/mobilevit/config/detection/ssd_mobilenext_320.yaml", line 9, column 1
could not find expected ':'
  in "/nfs/projects/mbzuai/ashaker_2/mobilevit/config/detection/ssd_mobilenext_320.yaml", line 10, column 13
Namespace(**{'adjust_bn_momentum.anneal_type': 'cosine', 'adjust_bn_momentum.enable': False, 'adjust_bn_momentum.final_momentum_value': 1e-06, 'common.accum_after_epoch': 0, 'common.accum_freq': 1, 'common.auto_resume': False, 'common.config_file': '/nfs/projects/mbzuai/ashaker_2/mobilevit/config/detection/ssd_mobilenext_320.yaml', 'common.finetune': None, 'common.finetune_ema': None, 'common.grad_clip': None, 'common.k_best_checkpoints': 5, 'common.log_freq': 100, 'common.mixed_precision': False, 'common.results_loc': '/result_detection2', 'common.resume': None, 'common.run_label': 'run_1', 'common.seed': 0, 'common.stats_only': True, 'dataset.augmentation.blur_kernel_range': None, 'dataset.augmentation.gamma_corr_range': None, 'dataset.augmentation.gauss_noise_var': None, 'dataset.augmentation.jpeg_q_range': None, 'dataset.augmentation.rotate_angle': None, 'dataset.augmentation.translate_factor': None, 'dataset.category': 'classification', 'dataset.eval_batch_size0': 1, 'dataset.name': 'imagenet', 'dataset.pascal.coco_root_dir': None, 'dataset.pascal.use_coco_data': False, 'dataset.persistent_workers': False, 'dataset.pin_memory': False, 'dataset.root_test': '', 'dataset.root_train': '/nfs/projects/mbzuai/salman/imagenet_1k/train', 'dataset.root_val': '/nfs/projects/mbzuai/salman/imagenet_1k/val', 'dataset.train_batch_size0': 64, 'dataset.val_batch_size0': 1, 'dataset.workers': 6, 'ddp.dist_port': 6006, 'ddp.dist_url': None, 'ddp.enable': False, 'ddp.rank': 0, 'ddp.world_size': 1, 'ema.copy_at_epoch': -1, 'ema.enable': False, 'ema.momentum': 0.0001, 'image_augmentation.box_absolute_coords.enable': False, 'image_augmentation.box_percent_coords.enable': False, 'image_augmentation.center_crop.enable': False, 'image_augmentation.photo_metric_distort.alpha_max': 1.5, 'image_augmentation.photo_metric_distort.alpha_min': 0.5, 'image_augmentation.photo_metric_distort.beta_max': 0.2, 'image_augmentation.photo_metric_distort.beta_min': -0.2, 'image_augmentation.photo_metric_distort.delta_max': 0.05, 'image_augmentation.photo_metric_distort.delta_min': -0.05, 'image_augmentation.photo_metric_distort.enable': False, 'image_augmentation.photo_metric_distort.gamma_max': 1.5, 'image_augmentation.photo_metric_distort.gamma_min': 0.5, 'image_augmentation.photo_metric_distort.p': 0.5, 'image_augmentation.random_blur.enable': False, 'image_augmentation.random_blur.kernel_size': [3, 7], 'image_augmentation.random_blur.kernel_type': 255, 'image_augmentation.random_blur.p': 0.5, 'image_augmentation.random_crop.enable': False, 'image_augmentation.random_crop.mask_fill': 255, 'image_augmentation.random_crop.resize_if_needed': False, 'image_augmentation.random_flip.enable': False, 'image_augmentation.random_gamma_correction.enable': False, 'image_augmentation.random_gamma_correction.gamma': (0.5, 1.5), 'image_augmentation.random_gamma_correction.p': 0.5, 'image_augmentation.random_gauss_noise.enable': False, 'image_augmentation.random_gauss_noise.p': 0.5, 'image_augmentation.random_gauss_noise.sigma': (0.03, 0.1), 'image_augmentation.random_horizontal_flip.enable': False, 'image_augmentation.random_horizontal_flip.p': 0.5, 'image_augmentation.random_jpeg_compress.enable': False, 'image_augmentation.random_jpeg_compress.p': 0.5, 'image_augmentation.random_jpeg_compress.q_factor': (5, 25), 'image_augmentation.random_order.apply_k': 1.0, 'image_augmentation.random_order.enable': False, 'image_augmentation.random_resize.enable': False, 'image_augmentation.random_resize.interpolation': 'bilinear', 'image_augmentation.random_resize.max_size': 1024, 'image_augmentation.random_resize.min_size': 256, 'image_augmentation.random_resized_crop.aspect_ratio': (0.75, 1.3333333333333333), 'image_augmentation.random_resized_crop.enable': False, 'image_augmentation.random_resized_crop.interpolation': 'bilinear', 'image_augmentation.random_resized_crop.scale': (0.08, 1.0), 'image_augmentation.random_rotate.angle': 10.0, 'image_augmentation.random_rotate.enable': False, 'image_augmentation.random_rotate.fill_mask': 255, 'image_augmentation.random_rotate.interpolation': 'bilinear', 'image_augmentation.random_rotate.p': 0.5, 'image_augmentation.random_scale.enable': False, 'image_augmentation.random_scale.interpolation': 'bilinear', 'image_augmentation.random_scale.max_scale': 2.0, 'image_augmentation.random_scale.min_scale': 0.5, 'image_augmentation.random_translate.enable': False, 'image_augmentation.random_translate.factor': 0.2, 'image_augmentation.random_vertical_flip.enable': False, 'image_augmentation.random_vertical_flip.p': 0.5, 'image_augmentation.random_zoom_out.enable': False, 'image_augmentation.random_zoom_out.p': 0.5, 'image_augmentation.random_zoom_out.side_range': [1, 4], 'image_augmentation.resize.enable': False, 'image_augmentation.resize.interpolation': 'bilinear', 'image_augmentation.resize.no_maintain_aspect_ratio': False, 'loss.category': 'classification', 'loss.classification.cross_entropy_class_weights': False, 'loss.classification.label_smoothing_factor': 0.1, 'loss.classification.name': 'cross_entropy', 'loss.detection.name': 'cross_entropy', 'loss.detection.ssd_multibox_loss.max_monitor_iter': -1, 'loss.detection.ssd_multibox_loss.neg_pos_ratio': 3, 'loss.detection.ssd_multibox_loss.update_wt_freq': 200, 'loss.distillation.name': 'vanilla', 'loss.distillation.vanilla_accum_iterations': 10000, 'loss.distillation.vanilla_adaptive_weight_balance': False, 'loss.distillation.vanilla_alpha': 0.5, 'loss.distillation.vanilla_distillation_type': 'soft', 'loss.distillation.vanilla_label_loss': 'cross_entropy', 'loss.distillation.vanilla_tau': 1.0, 'loss.distillation.vanilla_teacher_model': 'resnet_50', 'loss.distillation.vanilla_teacher_model_weights': None, 'loss.distillation.vanilla_weight_update_freq': 100, 'loss.ignore_idx': -1, 'loss.segmentation.cross_entropy_aux_weight': 0.4, 'loss.segmentation.cross_entropy_class_weights': False, 'loss.segmentation.name': 'cross_entropy', 'model.activation.inplace': False, 'model.activation.name': 'relu', 'model.activation.neg_slope': 0.1, 'model.classification.activation.inplace': False, 'model.classification.activation.name': None, 'model.classification.activation.neg_slope': 0.1, 'model.classification.classifier_dropout': 0.0, 'model.classification.freeze_batch_norm': False, 'model.classification.mit.attn_dropout': 0.1, 'model.classification.mit.conv_kernel_size': 3, 'model.classification.mit.dropout': 0.1, 'model.classification.mit.ffn_dropout': 0.0, 'model.classification.mit.head_dim': None, 'model.classification.mit.mode': None, 'model.classification.mit.no_fuse_local_global_features': False, 'model.classification.mit.number_heads': None, 'model.classification.mit.transformer_norm_layer': 'layer_norm', 'model.classification.mobilenetv2.width_multiplier': 1.0, 'model.classification.n_classes': 1000, 'model.classification.name': 'mobilenetv2', 'model.classification.pretrained': None, 'model.classification.resnet.depth': 50, 'model.detection.freeze_batch_norm': False, 'model.detection.n_classes': None, 'model.detection.name': None, 'model.detection.output_stride': None, 'model.detection.pretrained': None, 'model.detection.replace_stride_with_dilation': False, 'model.detection.ssd.anchors_aspect_ratio': [[2, 3], [2, 3], [2, 3], [2, 3], [2, 3]], 'model.detection.ssd.center_variance': 0.1, 'model.detection.ssd.conf_threshold': 0.05, 'model.detection.ssd.iou_threshold': 0.45, 'model.detection.ssd.max_box_size': 1.05, 'model.detection.ssd.min_box_size': 0.1, 'model.detection.ssd.nms_iou_threshold': 0.3, 'model.detection.ssd.num_objects_per_class': 200, 'model.detection.ssd.output_strides': [16, 32, 64, 128, -1], 'model.detection.ssd.proj_channels': [128, 256, 384, 512, 768], 'model.detection.ssd.size_variance': 0.2, 'model.layer.conv_init': 'kaiming_normal', 'model.layer.conv_init_std_dev': None, 'model.layer.global_pool': 'mean', 'model.layer.group_linear_init': 'xavier_uniform', 'model.layer.group_linear_init_std_dev': 0.01, 'model.layer.linear_init': 'xavier_uniform', 'model.layer.linear_init_std_dev': 0.01, 'model.normalization.groups': 32, 'model.normalization.momentum': 0.1, 'model.normalization.name': 'batch_norm', 'model.segmentation.activation.inplace': False, 'model.segmentation.activation.name': None, 'model.segmentation.activation.neg_slope': 0.1, 'model.segmentation.classifier_dropout': 0.1, 'model.segmentation.deeplabv3.aspp_dropout': 0.1, 'model.segmentation.deeplabv3.aspp_out_channels': 256, 'model.segmentation.deeplabv3.aspp_rates': (6, 12, 18), 'model.segmentation.deeplabv3.aspp_sep_conv': False, 'model.segmentation.freeze_batch_norm': False, 'model.segmentation.lr_multiplier': 1.0, 'model.segmentation.n_classes': None, 'model.segmentation.name': None, 'model.segmentation.output_stride': None, 'model.segmentation.pretrained': None, 'model.segmentation.replace_stride_with_dilation': False, 'model.segmentation.seg_head': 'basic', 'model.segmentation.use_aux_head': False, 'model.segmentation.use_level5_exp': False, 'optim.adam.amsgrad': False, 'optim.adam.beta1': 0.9, 'optim.adam.beta2': 0.98, 'optim.adamw.amsgrad': False, 'optim.adamw.beta1': 0.9, 'optim.adamw.beta2': 0.98, 'optim.eps': 1e-08, 'optim.name': 'sgd', 'optim.no_decay_bn_filter_bias': False, 'optim.sgd.momentum': 0.9, 'optim.sgd.nesterov': False, 'optim.weight_decay': 4e-05, 'sampler.bs.crop_size_height': 256, 'sampler.bs.crop_size_width': 256, 'sampler.name': 'batch_sampler', 'sampler.vbs.check_scale': 32, 'sampler.vbs.crop_size_height': 256, 'sampler.vbs.crop_size_width': 256, 'sampler.vbs.ep_intervals': [40], 'sampler.vbs.max_crop_size_height': 320, 'sampler.vbs.max_crop_size_width': 320, 'sampler.vbs.max_n_scales': 5, 'sampler.vbs.min_crop_size_height': 160, 'sampler.vbs.min_crop_size_width': 160, 'sampler.vbs.scale_inc': False, 'sampler.vbs.scale_inc_factor': 0.25, 'scheduler.cosine.max_lr': 0.1, 'scheduler.cosine.min_lr': 1e-05, 'scheduler.cyclic.epochs_per_cycle': 5, 'scheduler.cyclic.gamma': 0.5, 'scheduler.cyclic.last_cycle_end_lr': 0.001, 'scheduler.cyclic.last_cycle_type': 'linear', 'scheduler.cyclic.min_lr': 0.1, 'scheduler.cyclic.steps': None, 'scheduler.cyclic.total_cycles': 11, 'scheduler.is_iteration_based': False, 'scheduler.lr': 0.1, 'scheduler.max_epochs': None, 'scheduler.max_iterations': None, 'scheduler.name': 'cosine', 'scheduler.polynomial.end_lr': 1e-05, 'scheduler.polynomial.power': 2.5, 'scheduler.polynomial.start_lr': 0.1, 'scheduler.warmup_init_lr': 1e-07, 'scheduler.warmup_iterations': 0, 'stats.checkpoint_metric': None, 'stats.checkpoint_metric_max': None, 'stats.name': ['loss']})
2022-05-25 03:59:21 - [34m[1mLOGS   [0m - Random seeds are set to 0
2022-05-25 03:59:21 - [34m[1mLOGS   [0m - Using PyTorch version 1.11.0+cu102
2022-05-25 03:59:21 - [34m[1mLOGS   [0m - Available GPUs: 1
2022-05-25 03:59:21 - [34m[1mLOGS   [0m - CUDNN is enabled
2022-05-25 04:07:34 - [34m[1mLOGS   [0m - Training and validation dataset details: 
ImagenetDataset(
	root=/nfs/projects/mbzuai/salman/imagenet_1k/train
	 is_training=True
	samples=1281167
	transforms=Compose(
			RandomResizedCrop(scale=(0.08, 1.0), ratio=(0.75, 1.333), interpolation=bilinear), 
			NumpyToTensor(), 
			Normalize())
)
ImagenetDataset(
	root=/nfs/projects/mbzuai/salman/imagenet_1k/val
	 is_training=False
	samples=50000
	transforms=Compose(
			Resize(size=292, interpolation=bilinear), 
			CenterCrop(size=(h=256, w=256)), 
			NumpyToTensor(), 
			Normalize())
)
2022-05-25 04:07:34 - [34m[1mLOGS   [0m - Training sampler details: 
BatchSampler(
 	 base_im_size=(h=256, w=256)
 	 base_batch_size=64
	
)
2022-05-25 04:07:34 - [34m[1mLOGS   [0m - Validation sampler details: 
BatchSampler(
 	 base_im_size=(h=256, w=256)
 	 base_batch_size=1
	
)
2022-05-25 04:07:34 - [34m[1mLOGS   [0m - Number of data workers: 6
2022-05-25 04:07:34 - [34m[1mLOGS   [0m - Setting max. epochs to 300
2022-05-25 04:07:34 - [34m[1mLOGS   [0m - Max. epochs for training: 300
device is  cuda
Inside 1 GPU
Warning: module Conv2d is treated as a zero-op.
Warning: module BatchNorm2d is treated as a zero-op.
Warning: module ReLU is treated as a zero-op.
Warning: module ConvLayer is treated as a zero-op.
Warning: module InvertedResidual is treated as a zero-op.
Warning: module GlobalPool is treated as a zero-op.
Warning: module LinearLayer is treated as a zero-op.
Warning: module MobileNetV2 is treated as a zero-op.
MobileNetV2(
  0, 0.000% Params, 0.0 Mac, 0.000% MACs, 
  (conv_1): Conv2d(0, 0.000% Params, 0.0 Mac, 0.000% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False, normalization=BatchNorm2d, activation=ReLU, bias=False)
  (layer_1): Sequential(
    0, 0.000% Params, 0.0 Mac, 0.000% MACs, 
    (mv2_block_0): InvertedResidual(in_channels=32, out_channels=16, stride=1, exp=1, dilation=1)
  )
  (layer_2): Sequential(
    0, 0.000% Params, 0.0 Mac, 0.000% MACs, 
    (mv2_block_0): InvertedResidual(in_channels=16, out_channels=24, stride=2, exp=6, dilation=1)
    (mv2_block_1): InvertedResidual(in_channels=24, out_channels=24, stride=1, exp=6, dilation=1)
  )
  (layer_3): Sequential(
    0, 0.000% Params, 0.0 Mac, 0.000% MACs, 
    (mv2_block_0): InvertedResidual(in_channels=24, out_channels=32, stride=2, exp=6, dilation=1)
    (mv2_block_1): InvertedResidual(in_channels=32, out_channels=32, stride=1, exp=6, dilation=1)
    (mv2_block_2): InvertedResidual(in_channels=32, out_channels=32, stride=1, exp=6, dilation=1)
  )
  (layer_4): Sequential(
    0, 0.000% Params, 0.0 Mac, 0.000% MACs, 
    (mv2_block_0): InvertedResidual(in_channels=32, out_channels=64, stride=2, exp=6, dilation=1)
    (mv2_block_1): InvertedResidual(in_channels=64, out_channels=64, stride=1, exp=6, dilation=1)
    (mv2_block_2): InvertedResidual(in_channels=64, out_channels=64, stride=1, exp=6, dilation=1)
    (mv2_block_3): InvertedResidual(in_channels=64, out_channels=64, stride=1, exp=6, dilation=1)
    (mv2_block_4): InvertedResidual(in_channels=64, out_channels=96, stride=1, exp=6, dilation=1)
    (mv2_block_5): InvertedResidual(in_channels=96, out_channels=96, stride=1, exp=6, dilation=1)
    (mv2_block_6): InvertedResidual(in_channels=96, out_channels=96, stride=1, exp=6, dilation=1)
  )
  (layer_5): Sequential(
    0, 0.000% Params, 0.0 Mac, 0.000% MACs, 
    (mv2_block_0): InvertedResidual(in_channels=96, out_channels=160, stride=2, exp=6, dilation=1)
    (mv2_block_1): InvertedResidual(in_channels=160, out_channels=160, stride=1, exp=6, dilation=1)
    (mv2_block_2): InvertedResidual(in_channels=160, out_channels=160, stride=1, exp=6, dilation=1)
    (mv2_block_3): InvertedResidual(in_channels=160, out_channels=320, stride=1, exp=6, dilation=1)
  )
  (conv_1x1_exp): Conv2d(0, 0.000% Params, 0.0 Mac, 0.000% MACs, 320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False, normalization=BatchNorm2d, activation=ReLU, bias=False)
  (classifier): Sequential(
    0, 0.000% Params, 0.0 Mac, 0.000% MACs, 
    (global_pool): GlobalPool(type=mean)
    (classifier_fc): LinearLayer(in_features=1280, out_features=1000, bias=True)
  )
)
Params & Flops using ptflops:
Computational complexity:       0.0 Mac 
Number of parameters:           3.5 M   
+------------------------------------------------------+------------+
|                       Modules                        | Parameters |
+------------------------------------------------------+------------+
|               conv_1.block.conv.weight               |    864     |
|               conv_1.block.norm.weight               |     32     |
|                conv_1.block.norm.bias                |     32     |
| layer_1.mv2_block_0.block.conv_3x3.block.conv.weight |    288     |
| layer_1.mv2_block_0.block.conv_3x3.block.norm.weight |     32     |
|  layer_1.mv2_block_0.block.conv_3x3.block.norm.bias  |     32     |
| layer_1.mv2_block_0.block.red_1x1.block.conv.weight  |    512     |
| layer_1.mv2_block_0.block.red_1x1.block.norm.weight  |     16     |
|  layer_1.mv2_block_0.block.red_1x1.block.norm.bias   |     16     |
| layer_2.mv2_block_0.block.exp_1x1.block.conv.weight  |    1536    |
| layer_2.mv2_block_0.block.exp_1x1.block.norm.weight  |     96     |
|  layer_2.mv2_block_0.block.exp_1x1.block.norm.bias   |     96     |
| layer_2.mv2_block_0.block.conv_3x3.block.conv.weight |    864     |
| layer_2.mv2_block_0.block.conv_3x3.block.norm.weight |     96     |
|  layer_2.mv2_block_0.block.conv_3x3.block.norm.bias  |     96     |
| layer_2.mv2_block_0.block.red_1x1.block.conv.weight  |    2304    |
| layer_2.mv2_block_0.block.red_1x1.block.norm.weight  |     24     |
|  layer_2.mv2_block_0.block.red_1x1.block.norm.bias   |     24     |
| layer_2.mv2_block_1.block.exp_1x1.block.conv.weight  |    3456    |
| layer_2.mv2_block_1.block.exp_1x1.block.norm.weight  |    144     |
|  layer_2.mv2_block_1.block.exp_1x1.block.norm.bias   |    144     |
| layer_2.mv2_block_1.block.conv_3x3.block.conv.weight |    1296    |
| layer_2.mv2_block_1.block.conv_3x3.block.norm.weight |    144     |
|  layer_2.mv2_block_1.block.conv_3x3.block.norm.bias  |    144     |
| layer_2.mv2_block_1.block.red_1x1.block.conv.weight  |    3456    |
| layer_2.mv2_block_1.block.red_1x1.block.norm.weight  |     24     |
|  layer_2.mv2_block_1.block.red_1x1.block.norm.bias   |     24     |
| layer_3.mv2_block_0.block.exp_1x1.block.conv.weight  |    3456    |
| layer_3.mv2_block_0.block.exp_1x1.block.norm.weight  |    144     |
|  layer_3.mv2_block_0.block.exp_1x1.block.norm.bias   |    144     |
| layer_3.mv2_block_0.block.conv_3x3.block.conv.weight |    1296    |
| layer_3.mv2_block_0.block.conv_3x3.block.norm.weight |    144     |
|  layer_3.mv2_block_0.block.conv_3x3.block.norm.bias  |    144     |
| layer_3.mv2_block_0.block.red_1x1.block.conv.weight  |    4608    |
| layer_3.mv2_block_0.block.red_1x1.block.norm.weight  |     32     |
|  layer_3.mv2_block_0.block.red_1x1.block.norm.bias   |     32     |
| layer_3.mv2_block_1.block.exp_1x1.block.conv.weight  |    6144    |
| layer_3.mv2_block_1.block.exp_1x1.block.norm.weight  |    192     |
|  layer_3.mv2_block_1.block.exp_1x1.block.norm.bias   |    192     |
| layer_3.mv2_block_1.block.conv_3x3.block.conv.weight |    1728    |
| layer_3.mv2_block_1.block.conv_3x3.block.norm.weight |    192     |
|  layer_3.mv2_block_1.block.conv_3x3.block.norm.bias  |    192     |
| layer_3.mv2_block_1.block.red_1x1.block.conv.weight  |    6144    |
| layer_3.mv2_block_1.block.red_1x1.block.norm.weight  |     32     |
|  layer_3.mv2_block_1.block.red_1x1.block.norm.bias   |     32     |
| layer_3.mv2_block_2.block.exp_1x1.block.conv.weight  |    6144    |
| layer_3.mv2_block_2.block.exp_1x1.block.norm.weight  |    192     |
|  layer_3.mv2_block_2.block.exp_1x1.block.norm.bias   |    192     |
| layer_3.mv2_block_2.block.conv_3x3.block.conv.weight |    1728    |
| layer_3.mv2_block_2.block.conv_3x3.block.norm.weight |    192     |
|  layer_3.mv2_block_2.block.conv_3x3.block.norm.bias  |    192     |
| layer_3.mv2_block_2.block.red_1x1.block.conv.weight  |    6144    |
| layer_3.mv2_block_2.block.red_1x1.block.norm.weight  |     32     |
|  layer_3.mv2_block_2.block.red_1x1.block.norm.bias   |     32     |
| layer_4.mv2_block_0.block.exp_1x1.block.conv.weight  |    6144    |
| layer_4.mv2_block_0.block.exp_1x1.block.norm.weight  |    192     |
|  layer_4.mv2_block_0.block.exp_1x1.block.norm.bias   |    192     |
| layer_4.mv2_block_0.block.conv_3x3.block.conv.weight |    1728    |
| layer_4.mv2_block_0.block.conv_3x3.block.norm.weight |    192     |
|  layer_4.mv2_block_0.block.conv_3x3.block.norm.bias  |    192     |
| layer_4.mv2_block_0.block.red_1x1.block.conv.weight  |   12288    |
| layer_4.mv2_block_0.block.red_1x1.block.norm.weight  |     64     |
|  layer_4.mv2_block_0.block.red_1x1.block.norm.bias   |     64     |
| layer_4.mv2_block_1.block.exp_1x1.block.conv.weight  |   24576    |
| layer_4.mv2_block_1.block.exp_1x1.block.norm.weight  |    384     |
|  layer_4.mv2_block_1.block.exp_1x1.block.norm.bias   |    384     |
| layer_4.mv2_block_1.block.conv_3x3.block.conv.weight |    3456    |
| layer_4.mv2_block_1.block.conv_3x3.block.norm.weight |    384     |
|  layer_4.mv2_block_1.block.conv_3x3.block.norm.bias  |    384     |
| layer_4.mv2_block_1.block.red_1x1.block.conv.weight  |   24576    |
| layer_4.mv2_block_1.block.red_1x1.block.norm.weight  |     64     |
|  layer_4.mv2_block_1.block.red_1x1.block.norm.bias   |     64     |
| layer_4.mv2_block_2.block.exp_1x1.block.conv.weight  |   24576    |
| layer_4.mv2_block_2.block.exp_1x1.block.norm.weight  |    384     |
|  layer_4.mv2_block_2.block.exp_1x1.block.norm.bias   |    384     |
| layer_4.mv2_block_2.block.conv_3x3.block.conv.weight |    3456    |
| layer_4.mv2_block_2.block.conv_3x3.block.norm.weight |    384     |
|  layer_4.mv2_block_2.block.conv_3x3.block.norm.bias  |    384     |
| layer_4.mv2_block_2.block.red_1x1.block.conv.weight  |   24576    |
| layer_4.mv2_block_2.block.red_1x1.block.norm.weight  |     64     |
|  layer_4.mv2_block_2.block.red_1x1.block.norm.bias   |     64     |
| layer_4.mv2_block_3.block.exp_1x1.block.conv.weight  |   24576    |
| layer_4.mv2_block_3.block.exp_1x1.block.norm.weight  |    384     |
|  layer_4.mv2_block_3.block.exp_1x1.block.norm.bias   |    384     |
| layer_4.mv2_block_3.block.conv_3x3.block.conv.weight |    3456    |
| layer_4.mv2_block_3.block.conv_3x3.block.norm.weight |    384     |
|  layer_4.mv2_block_3.block.conv_3x3.block.norm.bias  |    384     |
| layer_4.mv2_block_3.block.red_1x1.block.conv.weight  |   24576    |
| layer_4.mv2_block_3.block.red_1x1.block.norm.weight  |     64     |
|  layer_4.mv2_block_3.block.red_1x1.block.norm.bias   |     64     |
| layer_4.mv2_block_4.block.exp_1x1.block.conv.weight  |   24576    |
| layer_4.mv2_block_4.block.exp_1x1.block.norm.weight  |    384     |
|  layer_4.mv2_block_4.block.exp_1x1.block.norm.bias   |    384     |
| layer_4.mv2_block_4.block.conv_3x3.block.conv.weight |    3456    |
| layer_4.mv2_block_4.block.conv_3x3.block.norm.weight |    384     |
|  layer_4.mv2_block_4.block.conv_3x3.block.norm.bias  |    384     |
| layer_4.mv2_block_4.block.red_1x1.block.conv.weight  |   36864    |
| layer_4.mv2_block_4.block.red_1x1.block.norm.weight  |     96     |
|  layer_4.mv2_block_4.block.red_1x1.block.norm.bias   |     96     |
| layer_4.mv2_block_5.block.exp_1x1.block.conv.weight  |   55296    |
| layer_4.mv2_block_5.block.exp_1x1.block.norm.weight  |    576     |
|  layer_4.mv2_block_5.block.exp_1x1.block.norm.bias   |    576     |
| layer_4.mv2_block_5.block.conv_3x3.block.conv.weight |    5184    |
| layer_4.mv2_block_5.block.conv_3x3.block.norm.weight |    576     |
|  layer_4.mv2_block_5.block.conv_3x3.block.norm.bias  |    576     |
| layer_4.mv2_block_5.block.red_1x1.block.conv.weight  |   55296    |
| layer_4.mv2_block_5.block.red_1x1.block.norm.weight  |     96     |
|  layer_4.mv2_block_5.block.red_1x1.block.norm.bias   |     96     |
| layer_4.mv2_block_6.block.exp_1x1.block.conv.weight  |   55296    |
| layer_4.mv2_block_6.block.exp_1x1.block.norm.weight  |    576     |
|  layer_4.mv2_block_6.block.exp_1x1.block.norm.bias   |    576     |
| layer_4.mv2_block_6.block.conv_3x3.block.conv.weight |    5184    |
| layer_4.mv2_block_6.block.conv_3x3.block.norm.weight |    576     |
|  layer_4.mv2_block_6.block.conv_3x3.block.norm.bias  |    576     |
| layer_4.mv2_block_6.block.red_1x1.block.conv.weight  |   55296    |
| layer_4.mv2_block_6.block.red_1x1.block.norm.weight  |     96     |
|  layer_4.mv2_block_6.block.red_1x1.block.norm.bias   |     96     |
| layer_5.mv2_block_0.block.exp_1x1.block.conv.weight  |   55296    |
| layer_5.mv2_block_0.block.exp_1x1.block.norm.weight  |    576     |
|  layer_5.mv2_block_0.block.exp_1x1.block.norm.bias   |    576     |
| layer_5.mv2_block_0.block.conv_3x3.block.conv.weight |    5184    |
| layer_5.mv2_block_0.block.conv_3x3.block.norm.weight |    576     |
|  layer_5.mv2_block_0.block.conv_3x3.block.norm.bias  |    576     |
| layer_5.mv2_block_0.block.red_1x1.block.conv.weight  |   92160    |
| layer_5.mv2_block_0.block.red_1x1.block.norm.weight  |    160     |
|  layer_5.mv2_block_0.block.red_1x1.block.norm.bias   |    160     |
| layer_5.mv2_block_1.block.exp_1x1.block.conv.weight  |   153600   |
| layer_5.mv2_block_1.block.exp_1x1.block.norm.weight  |    960     |
|  layer_5.mv2_block_1.block.exp_1x1.block.norm.bias   |    960     |
| layer_5.mv2_block_1.block.conv_3x3.block.conv.weight |    8640    |
| layer_5.mv2_block_1.block.conv_3x3.block.norm.weight |    960     |
|  layer_5.mv2_block_1.block.conv_3x3.block.norm.bias  |    960     |
| layer_5.mv2_block_1.block.red_1x1.block.conv.weight  |   153600   |
| layer_5.mv2_block_1.block.red_1x1.block.norm.weight  |    160     |
|  layer_5.mv2_block_1.block.red_1x1.block.norm.bias   |    160     |
| layer_5.mv2_block_2.block.exp_1x1.block.conv.weight  |   153600   |
| layer_5.mv2_block_2.block.exp_1x1.block.norm.weight  |    960     |
|  layer_5.mv2_block_2.block.exp_1x1.block.norm.bias   |    960     |
| layer_5.mv2_block_2.block.conv_3x3.block.conv.weight |    8640    |
| layer_5.mv2_block_2.block.conv_3x3.block.norm.weight |    960     |
|  layer_5.mv2_block_2.block.conv_3x3.block.norm.bias  |    960     |
| layer_5.mv2_block_2.block.red_1x1.block.conv.weight  |   153600   |
| layer_5.mv2_block_2.block.red_1x1.block.norm.weight  |    160     |
|  layer_5.mv2_block_2.block.red_1x1.block.norm.bias   |    160     |
| layer_5.mv2_block_3.block.exp_1x1.block.conv.weight  |   153600   |
| layer_5.mv2_block_3.block.exp_1x1.block.norm.weight  |    960     |
|  layer_5.mv2_block_3.block.exp_1x1.block.norm.bias   |    960     |
| layer_5.mv2_block_3.block.conv_3x3.block.conv.weight |    8640    |
| layer_5.mv2_block_3.block.conv_3x3.block.norm.weight |    960     |
|  layer_5.mv2_block_3.block.conv_3x3.block.norm.bias  |    960     |
| layer_5.mv2_block_3.block.red_1x1.block.conv.weight  |   307200   |
| layer_5.mv2_block_3.block.red_1x1.block.norm.weight  |    320     |
|  layer_5.mv2_block_3.block.red_1x1.block.norm.bias   |    320     |
|            conv_1x1_exp.block.conv.weight            |   409600   |
|            conv_1x1_exp.block.norm.weight            |    1280    |
|             conv_1x1_exp.block.norm.bias             |    1280    |
|           classifier.classifier_fc.weight            |  1280000   |
|            classifier.classifier_fc.bias             |    1000    |
Unsupported operator aten::add encountered 10 time(s)
Unsupported operator aten::mean encountered 1 time(s)
+------------------------------------------------------+------------+
Total Trainable Params: 3.5 M
Flops using fvcore: 409.9 M
    #Activations : 8.7224 [M]
         #Conv2d : 52
           FLOPs : 0.4166 [G]
         #Params : 3.5049 [M]
FPS @ BS=1: 273.83
Total passes to network: 30
Batch size: 256
Total network time: 2.099083662033081 sec
Throughput: 3658.7393532287733 FPS
